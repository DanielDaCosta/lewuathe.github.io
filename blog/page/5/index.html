
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>The first cry of Atom</title>
  <meta name="author" content="Kai Sasaki">

  
  <meta name="description" content="だんだんとscikit-learnとMachine Learningに慣れてきた。
今回はCross ValidationとGrid Searchをやってみた。 Cross Validation 詳しいことはWikipediaに書いてある。
Cross &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content=" - The first cry of Atom" >
<meta property="og:description" content="だんだんとscikit-learnとMachine Learningに慣れてきた。
今回はCross ValidationとGrid Searchをやってみた。 Cross Validation 詳しいことはWikipediaに書いてある。
Cross &hellip;" />
<meta property="og:url" content="http://lewuathe.com" />
<meta property="og:image" content="http://lewuathe.github.io/images/site_image.png" />
<meta property="og:author" content="lewuathe" />
<meta property="og:site_name" content="The first cry of Atom" />
<meta property="og:locale" content="ja_JP" />
<meta property="og:type" content="blog" />
<meta property="fb:app_id" content="212934732101925" />


  
  <link rel="canonical" href="http://lewuathe.github.io/blog/page/5">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="The first cry of Atom" type="application/atom+xml">
  <link href="/stylesheets/data-table.css" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-44055098-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">The first cry of Atom</a></h1>
  
    <h2>The people who are crazy enough to think thay can change the world, are the ones who do</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:lewuathe.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about.html">About</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="http://fotologue.jp/lewuathe">Pictures</a></li>
  <li><a href="https://github.com/Lewuathe">GitHub</a></li>
  <li><a href="https://twitter.com/Lewuathe">Twitter</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/09/scikit-learndecross-validation/">scikit-learnでCross Validation</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-09T21:56:00+09:00" pubdate data-updated="true">Nov 9<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>だんだんとscikit-learnとMachine Learningに慣れてきた。
今回はCross ValidationとGrid Searchをやってみた。</p>

<h3>Cross Validation</h3>

<p>詳しいことは<a href="http://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E6%A4%9C%E5%AE%9A">Wikipedia</a>に書いてある。
Cross Validationはモデルの妥当性を検証する方法のひとつ。一般的に開発用のデータは訓練データと検証データに分かれる。
しかし、このまま行ってしまうと折角の訓練データが減ってしまうことになる上に、訓練データの選び方によって汎化性能が下がってしまう可能性がある。
Wikipediaに書いてあるもののホールド・アウト検定がこれに当たる。一般にはこれはCross Validationにはあたらない。</p>

<p>ここに書いてあるK-分割交差検定がこれに当たる。K-分割交差検定では開発用のデータをK個に分割しK-1個を訓練用に、残りの一つを検証用に使いモデルの正当性を計算する。
これにより使える訓練データが増えると同時に、これらを訓練データを変えることにより、汎化性能を上げることができる。</p>

<p>scikit-learnで具体的にどのように行うのか書いてみた。訓練に使ったデータとしてはKaggleの<a href="http://www.kaggle.com/c/data-science-london-scikit-learn">Data Science London</a>で出されているものを用いた。</p>

<h3>SVM</h3>

<p>まずは単純にサポートベクターマシンでクラス分けをさせた時のコード</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># -*- coding: utf-8 -*-</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">os</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">csv</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="p">:</span>
</span><span class='line'>    <span class="n">train_feature_file</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/train.csv&quot;</span><span class="p">,</span> <span class="s">&quot;rb&quot;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class='line'>    <span class="n">train_label_file</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/trainLabels.csv&quot;</span><span class="p">,</span> <span class="s">&quot;rb&quot;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">train_features</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="n">train_labels</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">train_feature</span><span class="p">,</span> <span class="n">train_label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">train_feature_file</span><span class="p">,</span> <span class="n">train_label_file</span><span class="p">):</span>
</span><span class='line'>        <span class="n">train_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_feature</span><span class="p">)</span>
</span><span class='line'>        <span class="n">train_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_label</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">train_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_features</span><span class="p">)</span>
</span><span class='line'>    <span class="n">train_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_labels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cache_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">shrinking</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">test_feature_file</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">&quot;../data/test.csv&quot;</span><span class="p">,</span> <span class="s">&quot;rb&quot;</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">&quot;,&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">test_features</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="k">print</span> <span class="s">&quot;Id,Solution&quot;</span>
</span><span class='line'>    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">test_feature</span> <span class="ow">in</span> <span class="n">test_feature_file</span><span class="p">:</span>
</span><span class='line'>        <span class="k">print</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_feature</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
</span><span class='line'>        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span></code></pre></td></tr></table></div></figure>


<p>このモデルをCross Validationで検証してみる。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span class='line'>    <span class="k">print</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>cross_validation.train_test_splitは一定の割合が検証用データとなるように開発用データを分割する関数。この場合は<code>test_size=0.4</code>を指定したので、40%のデータを検証用として使うことになる。
<code>fit</code>が60%の訓練データで行うもので、scoreが残された40%のデータで検証を行いその正答率を出してくれる。これがこのモデルの、このテストデータにおける正当性となる。もちろんこれが高ければ高いほどよいが
汎化性能が高いかどうかはここからでは読み取ることができない。そのためK分割を行うことでK回の検証を行うことができる。これらのスコアを平均することで汎化性能も含めたモデルの正当性を表すことができる。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span class='line'>    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Accuracy: </span><span class="si">%0.2f</span><span class="s"> (+/- </span><span class="si">%0.2f</span><span class="s">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>cross_validation_cross_val_score</code>でこれらの検証のすべてのscoreを得ることができる。<code>cv</code>はK分割の分割の個数を指定することができる。今回は開発用のデータを10個に分割し10回の検証を行う。
scoresには10個のscoreが入ったリストが返ってくる。これの平均をAccuracyとして出している。これで汎化性能も含めたモデルの正当性を得ることができるが、モデルパラメータのチューニングを手で行う必要がある。
手で調整して、Accuracyを計算するというのは非常に手間なのでGrid Searchというアルゴリズムでこのチューニングをある程度自動化することができる。</p>

<h3>Grid Search</h3>

<p>パラメータの範囲を指定することで経験的に最適なパラメータの組を探索する方法がGrid Search。Pythonで行うには以下のように書く。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">grid_search</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">):</span>
</span><span class='line'>    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s">&#39;linear&#39;</span><span class="p">]},</span>
</span><span class='line'>        <span class="p">{</span><span class="s">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span> <span class="s">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s">&#39;rbf&#39;</span><span class="p">]},</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</span><span class='line'>    <span class="k">print</span> <span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span>
</span></code></pre></td></tr></table></div></figure>


<p>param_gridに指定することでこの範囲を指定することができる。n_jobsに並列に計算を行うプロセス数を指定することができる。-1を指定するとコア数をデフォルト選ぶようになっている。与えられた訓練データに対してGrid Searchを行う。
時間は少しかかるが、この訓練データに対して最もスコアが高くなるようなモデルパラメータを選ぶことができる。この訓練データを実際のテストデータに使うことができる。</p>

<h3>まとめ</h3>

<p>PRMLには実際の機械学習のプロセスみたいなものがあまり細かく書かれていないのでKaggleに提出されているコードとかを実際にみて、こういったプロセスが分かるようになってきた。
あとscikit-learnが便利すぎて、機械学習の学習アルゴリズムだけじゃなくて特徴抽出とかモデルパラメータの最適化なども整備されていたことに驚いた。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/03/tf-idfdetagufu-ke/">TF-IDFでタグ付け</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-03T22:28:00+09:00" pubdate data-updated="true">Nov 3<span>rd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Kaggleで挑戦できそうな問題があったのでチャレンジしてみた。</p>

<p><a href="http://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction">http://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction</a></p>

<p>Stack Exchange(Stack Overflowみたいなもの)にあるテキストとそのタグデータを訓練データとして
同様にStack Exchangeにあるページからタグを類推せよという問題。
多分キーワード抽出を行う方法がうまく行くんじゃないかと思いやってみた。</p>

<h2>TF-IDFアルゴリズム</h2>

<p><img src="/images/posts/2013-11-03-tfidf/equation.png" alt="Equation" /></p>

<p>基本的にはTF-IDFを使ってみる。これは文書中のtokenの重要度をその頻度と、他の文書にどれくらいないかの指標
の積として表すアルゴリズム。コードで書くと下のような感じ。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'><span class="n">term</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Target</span> <span class="n">Term</span><span class="o">&gt;</span>
</span><span class='line'><span class="n">include_document_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">all_documents</span> <span class="k">if</span> <span class="n">term</span> <span class="ow">in</span> <span class="n">d</span><span class="p">])</span>
</span><span class='line'><span class="n">word_score</span> <span class="o">=</span> <span class="n">term_frequency</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span> <span class="n">all_document_num</span> <span class="o">/</span> <span class="n">include_document_num</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>term_frquencyはその文書中にどれくらいその単語が出てきたか。多くの場合は正規化してある。
その後ろの項は全文書中にその単語を含む文書がどれくらいあるかの比の逆数。これは他の文書にその単語がなければないほど大きくなるので、その単語がその文書のキーワードとして十分に機能することを示唆している。
TF-IDFのTFはTerm FrequencyでIDFはInversed Document Frequencyの略だ。</p>

<p>今回はTestデータの各文書の単語として有効な単語(htmlタグや各種記法は省くようにした)についてword_scoreを計算し、その中から正規化されたscoreが10%を超えたものをその文書のキーワードとして抽出するようにしてみた。
プログラムのコアの部分は以下のような形になった。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c"># 全テストデータ</span>
</span><span class='line'><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">test_file</span><span class="p">:</span>
</span><span class='line'>    <span class="c"># テストデータとしてタイトルもあるのでこいつも利用してみる</span>
</span><span class='line'>    <span class="n">title_tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># 英数字意外の文字を取り除いた</span>
</span><span class='line'>    <span class="n">tokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">r&quot;\W+&quot;</span><span class="p">,</span> <span class="n">nltk</span><span class="o">.</span><span class="n">clean_html</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># ここは自分でかってに付け足した部分。タイトルに含まれる単語達は特別扱いして10個余分に足しておく</span>
</span><span class='line'>  <span class="c"># 本当はここは文書中の何%とかにした方が各文書でのタイトルの重要度にばらつきがでなくていいのかもしれない</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">title_token</span> <span class="ow">in</span> <span class="n">title_tokens</span><span class="p">:</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
</span><span class='line'>            <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">title_token</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># 同じ単語のscoreを計算しても意味ないので重複を消しておく</span>
</span><span class='line'>    <span class="n">uniqTokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># 各tokenのscoreを計算。実際の計算はNLTKに任せた</span>
</span><span class='line'>    <span class="n">tf_idf_scores</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">uniqTokens</span><span class="p">:</span>
</span><span class='line'>        <span class="n">tf_idf_scores</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">collection</span><span class="o">.</span><span class="n">tf_idf</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># scoreでソート</span>
</span><span class='line'>    <span class="n">sorted_tf_idf_scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">tf_idf_scores</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># 10%を超えたものをkeywordsとして登録</span>
</span><span class='line'>    <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sorted_tf_idf_scores</span> <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">]</span>
</span><span class='line'>  <span class="c"># 1個もないのは変なので1番scoreが高いものだけでも抽出しておく</span>
</span><span class='line'>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">keywords</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span class='line'>        <span class="n">keywords</span> <span class="o">=</span> <span class="p">[</span> <span class="n">sorted_tf_idf_scores</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># ファイル出力</span>
</span><span class='line'>    <span class="n">result_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%s</span><span class="s">,</span><span class="se">\&quot;</span><span class="si">%s</span><span class="se">\&quot;\n</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">)))</span>
</span></code></pre></td></tr></table></div></figure>


<p>訓練データがあまりにもデカイので、ちょっと全部は訓練できない。
一部の訓練データに対して試してみて余分はかなり出てくるけれど、抜けは割りとない。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="err">推定キーワード</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><span class="s">&quot;an without type file image check uploaded mime&quot;</span>
</span><span class='line'><span class="err">正解キーワード</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><span class="s">&quot;php image-processing file-upload upload mime-types&quot;</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="err">推定キーワード</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span><span class="s">&quot;How ctrl press prevent firefox closing&quot;</span>
</span><span class='line'><span class="err">正解キーワード</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span><span class="s">&quot;firefox&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>image-processingとか、そもそもそういう単語を文書に含んでなかったらこの方法だと抽出できない。もっと関係抽出とか固有表現認識とかしないといけないかも。あとタイトルの重みを強くし過ぎたせいか&#8221;How&#8221;とか&#8221;Can&#8221;とかの単語も結構入ってきてしまう。Stack ExchangeとかStack Overflowって自分が書くときを考えてみてもそうだけど、単純に疑問文書くことも多いから単純にタイトルにキーワードが含まれているだろうという考えは甘いかも。</p>

<p>もう少しチューニングしてみる。あと訓練データが600万件近くあるのでできるだけたくさん利用できるように工夫したい。
(マシンスペックと時間を考えても100万件が今の限界・・・)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/25/osswoshi-u%2C-zuo-ru/">OSSを使う、作る</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-25T21:53:00+09:00" pubdate data-updated="true">Oct 25<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>昨日、以前作ったOSSのライブラリにpatchが送られてきた。</p>

<p><a href="https://github.com/Lewuathe/passport-yj">https://github.com/Lewuathe/passport-yj</a></p>

<p><img src="/images/posts/2013-10-25-oss/code.png" alt="passport-yj" /></p>

<p>友人とかなり昔に作ったので、存在を忘れていたとまではいかないがpatchが送られてきたときは驚いた。何したらいいんだろうという感じだった。
patchの内容はpassport-yjの依存しているpassportモジュールの仕様が変わったから対応したらーということで送ってくれた。</p>

<p>僕は正直passportの仕様をキャッチアップできていなかったので、こうやってpatchが送られてきて嬉しかった。</p>

<p>自分たちが作ったソフトウェアがよりよくなるということ、そして何よりどこかの誰かが使ってくれているということが目で見える形で分かったからだ。</p>

<p>patchを送ってくれた人は少なくとも日本人ではあるみたいだけれど僕とは縁もゆかりもない人だ。(もっとも顔写真もなにもないので、縁もゆかりも本当にないのかもよくわからない)
そんな人がどこかでこのライブラリを使って、改善点があったのでpatchを送ってくれた。送られたpatchを落としてきてテストして動作を確認する。僕自身も今までに大きなプロジェクト、小さなプロジェクトにちょこちょこpatchを送っていた。そこでディスカッションをしたり、取り込んでもらえたりもらえなかったり。そのコードはそういう意味で書いてあるのかと疑問が氷解したり。</p>

<p>そして気づいた。ああ、これがOSSへの貢献なんじゃないかと。</p>

<p>LinuxとかWebKitとか、大きなプロジェクトへの貢献を夢見てなんとなく憧れを抱いていたけど、今自分がやっていたことは紛れもなくOSS活動じゃないか。ずっとやりたいと思っていたことをいつの間にか僕はやっていた。誰かが仕事から帰ってちょこちょこっと作った小さなライブラリ僕が使い、僕が週末に作った小さなモジュールをどこかの誰かが使う。その誰かは日本の人かもしれないし、外国の人かもしれないし、人間ですらないかもしれない。(さっき見たら<a href="https://github.com/Lewuathe/node-jp">node-jp</a>はbotっぽいのにたくさんforkされてた)そういうコードを介した会話みたいなものはまさにソーシャルコーディングだし、僕はそれがやりたかった。</p>

<p>誰かが少しだけ世界を良くしようと思って作ったものを、他の誰かが使って実際に世界を少しだけ良くしている。大きさとか規模はあんまり関係なくて自分がそれを感じることができるかどうか。僕は見ず知らずの人からpatchが送られてくることでそれを感じた。</p>

<p>またいつでもpatchが来てもいいように、折角なので自動化テストを書いておこう。</p>

<p>きっと世界が少しだけ良くなると思う。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/20/dockerwoshi-tutemiyou/">Dockerで仮想化をはじめよう</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-20T20:30:00+09:00" pubdate data-updated="true">Oct 20<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>仮想環境構築の方法のひとつに<a href="http://www.docker.io/">Docker</a>を使ってみた。いままではVirtualBoxを使ってVagrantからつないでいく方法をやってみたけれど、仮想マシンをいちいち立ち上げる方法はどうも遅いのでDockerというもので試してみた。</p>

<p>Dockerの特徴は以下記事から抜粋。</p>

<p><a href="http://apatheia.info/blog/2013/06/17/docker/">http://apatheia.info/blog/2013/06/17/docker/</a></p>

<ul>
<li>仮想マシンを立ち上げるわけではなく、ホスト内の隔離された環境で動作するため起動が速い。<a href="http://linuxcontainers.org/">LXC</a>という技術のことらしい。ここでこの隔離されたシステムのことを <strong>コンテナ</strong> という。</li>
<li>AUFSを使っている。起動したときはディレクトリを重ねあわせておいて、更新の際に別の場所に書き込むというファイルシステムっぽい。立ち上げ時にイメージコピーがいらないので起動が軽い。</li>
</ul>


<h2>動かしてみた</h2>

<p>環境は以下で行った</p>

<ul>
<li>MacOSX 10.8</li>
<li>VirtualBox 4.2</li>
<li>vagrant 1.2.4</li>
</ul>


<p>他にUbuntu LTS12.04が入ったマシンを持っていたのでVagrant使わずにそっちでトライしたら32bitだとだめらしい。どうもUbuntu日本語コミュニティには32bitイメージしかなかったのでぼけーっと入れたらそっちになってしまったみたい。また入れなおすのもとりあえずめんどくさいのでMacのVagrantにUbuntu仮想マシンを立ち上げてその上にDockerを起動させるという構成。</p>

<p><a href="http://docs.docker.io/en/latest/installation/vagrant/">ここ</a>に従えば特に問題なくいけた。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git clone https://github.com/dotcloud/docker.git
</span><span class='line'>$ cd docker
</span><span class='line'>$ vagrant up</span></code></pre></td></tr></table></div></figure>


<p>ここまでで10minくらいかかる。でも悪いのはVirtualBoxとvagrant。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># dockerが起動するか見てみる
</span><span class='line'>$ docker
</span><span class='line'># サブコマンドがだーっと出る</span></code></pre></td></tr></table></div></figure>


<h2>イメージをダウンロード</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo docker pull ubuntu</span></code></pre></td></tr></table></div></figure>


<h2>先ほどのコンテナ内でスクリプトを動作させる</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># sudo docker run &lt;実行対象コンテナ&gt; &lt;コマンド(引数あってもいい)&gt;
</span><span class='line'>$ sudo docker run ubuntu /bin/echo hello world</span></code></pre></td></tr></table></div></figure>


<p>別にsudoはなくてもいい
これらはDockerのコンテナ内で実行されているコマンドだが、いまいち仮想ホスト立てている感じにならない。それを感じるためにはDockerをdaemon化させる必要がある。</p>

<h2>コマンドをdaemon化させる</h2>

<p>走らせるコマンドを定義する。このコマンドはコンテナのIDを返す。このIDをもとにそのコンテナで何がおきているかを見る
-dはコマンドをdaemon化させるオプション</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ CONTAINER_ID=$(sudo docker run -d ubuntu /bin/sh -c "while true; do echo hello world; sleep 1; done")</span></code></pre></td></tr></table></div></figure>


<p>そして起動させる。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo docker logs $CONTAINER_ID</span></code></pre></td></tr></table></div></figure>


<p>さっきのコンテナIDが返ってくるのでこいつを<code>docker logs</code>に渡してやると実行されているコマンドの値が見えるようになる。たただしこれは実行が終わったら返ってくるのでリアルタイムにコマンドの結果を見たければ<code>attach</code>を使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo docker attach $CONTAINER_ID</span></code></pre></td></tr></table></div></figure>


<p>ここまで適当にやっていったら、いっぱいコンテナができてしまったので確認してみる。dockerが起動したコマンドたちを確認する場合は<code>ps</code>サブコマンドを使う。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker ps
</span><span class='line'>ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
</span><span class='line'>4841794938a7        ubuntu:12.04        /bin/sh -c while tru   7 minutes ago       Up 7 minutes            
</span><span class='line'>79b862e271bc        ubuntu:12.04        /bin/sh -c while tru   8 minutes ago       Up 8 minutes                  
</span><span class='line'>bee9d7a00611        ubuntu:12.04        /bin/sh -c while tru   9 minutes ago       Up 9 minutes           </span></code></pre></td></tr></table></div></figure>


<p>こいつらをとめたければ<code>stop</code>を使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo docker stop 4841794938a7 
</span><span class='line'>4841794938a7 
</span><span class='line'>
</span><span class='line'>$ sudo docker ps
</span><span class='line'>ID                  IMAGE               COMMAND                CREATED             STATUS              PORTS
</span><span class='line'>79b862e271bc        ubuntu:12.04        /bin/sh -c while tru   13 minutes ago      Up 13 minutes             
</span><span class='line'>bee9d7a00611        ubuntu:12.04        /bin/sh -c while tru   14 minutes ago      Up 14 minutes                    </span></code></pre></td></tr></table></div></figure>


<h2>まとめ</h2>

<p>今回のチュートリアルは<a href="http://docs.docker.io/en/latest/examples/hello_world/#running-examples">ここ</a>からすべてとった。Dockerかなり簡単だけれど、いまいちコマンドをひとつひとつ打っているだけな気がして仮想マシンをたてて、実行している感じがあまりしない。ここで実際にWebアプリとか作ることとかもできるっぽいのでもうちょっと見ていこうかと。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/18/masutasenseihaxu-wotukanai/">マスターセンセイは嘘をつかない</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-18T22:25:00+09:00" pubdate data-updated="true">Oct 18<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>仕事で、あるアジャイルプロジェクトに関わってきた。</p>

<p>スクラムマスターとなり、初めてのアジャイルプロジェクトを進めてもう3ヶ月ほどになる。</p>

<p>今日、アジャイルのススメ方についてこれまでも指導をくれていた人から幾つか言葉をもらったので
これまでの３ヶ月、これからのこと、アジャイルですすめることの本質とか考えてみたのでまとめる。</p>

<p>ちなみにこの人は僕の中ではマスターセンセイと呼んでいるので、以下同一人物。</p>

<h2>無理はしない</h2>

<p>アジャイルの根底にある本質を一言で表せと言われたらこの言葉になると思う。無理はしないというと消極的に思われるかもしれないので
足るを知ると言ってもいいかもしれない。自分たちに何ができて何ができないかをきちんと知ろうという姿勢はあるような気がする。
毎日のデイリースクラムに遅刻してくるメンバーがいたら彼が来られるようにしてあげるか、あるいは彼が来られる時間にしてあげるかだ。
もちろん無理はあってはいけないから彼が無理しなくては来られないのであれば前者はなしだ。プロジェクトを進める上で無理はあってはいけない。
それはリスクの増加につながるからだ。</p>

<p><img src="/images/posts/2013-10-18-agile_scrum/daily_scrum.png" alt="Daily Scrum" /></p>

<h2>「使うかもしれない」はきっと「使わない」</h2>

<p>今考えられるユーザストーリとか、タスクとか。スクラムにあったら便利かもと思うようなツールとかスキーマとか。そういうものを
必要になっていないのに取り出しはじめるのは良くないということ。具体的に言おう。僕達は各タスクに「優先度シール」なるものを
貼っていたときがある。これはプロダクトバックログがまだ優先度順に並んでいなくてコンポーネントごとに貼り付けてしまっていたことが
原因だった。（つまり優先順位順に並べることができなかった）その中でも何を優先するべきかを表示するラベルを僕達は作った。そして捨てた。
もうユーザストーリリストごとにタスクをリストアップできるようになったからだ。それでも「優先度シール」あっても良かったかもしれない。
だっていつか「使うかもしれない」。またプロダクトバックログの順序がばらばらになる時がくるかもしれない。
悩んでいるとマスターセンセイは教えてくれた。</p>

<blockquote><p>でもそれは捨てるべきなんだ。</p></blockquote>


<p><img src="/images/posts/2013-10-18-agile_scrum/rolex.png" alt="Trash" /></p>

<p>必要になったらまた作ればいい。アジャイルというのは小回りを効かせるために身軽さを求めるものなのかもしれない。
プロジェクトのフレームワークに必要のなくなった「もの」は基本的にはその場から捨ててしまうのがいい。
アジャイルをすすめる前に決めたインセプションデッキの問いのひとつにはこんなものがある。</p>

<p>「なぜ僕たちはここにいるのか」</p>

<p>この「使うかもしれない」を増やしていくとこの問に答えづらくなっていってしまうんじゃないかな。と僕は思う。</p>

<p>ちなみにマスターセンセイは『<a href="http://www.amazon.co.jp/%E3%83%88%E3%83%A8%E3%82%BF%E3%81%AE%E7%89%87%E3%81%A5%E3%81%91-OJT%E3%82%BD%E3%83%AA%E3%83%A5%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%BA/dp/4806145483">トヨタの片付け</a>』という本も紹介してくれた。</p>

<h2>兼務はしない</h2>

<p>１人が１度に抱えるタスクは最大で２つまでだ。これは『<a href="http://www.amazon.co.jp/%E3%82%A2%E3%82%B8%E3%83%A3%E3%82%A4%E3%83%AB%E3%81%AA%E8%A6%8B%E7%A9%8D%E3%82%8A%E3%81%A8%E8%A8%88%E7%94%BB%E3%81%A5%E3%81%8F%E3%82%8A-~%E4%BE%A1%E5%80%A4%E3%81%82%E3%82%8B%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%E3%82%92%E8%82%B2%E3%81%A6%E3%82%8B%E6%A6%82%E5%BF%B5%E3%81%A8%E6%8A%80%E6%B3%95~-Mike-Cohn/dp/4839924023/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1382104183&amp;sr=1-1&amp;keywords=%E3%82%A2%E3%82%B8%E3%83%A3%E3%82%A4%E3%83%AB%E3%81%AA%E8%A6%8B%E7%A9%8D%E3%82%82%E3%82%8A%E3%81%A8%E8%A8%88%E7%94%BB%E3%81%A5%E3%81%8F%E3%82%8A">アジャイルな見積もりと計画づくり</a>』の中で語られているデータにもとづいている。その中で語られていることはこうだ。</p>

<ul>
<li>マルチタスク化は生産性に甚大な悪影響を与える</li>
<li>クラークとウィールライトによるマルチタスク化の研究で、個人が3つ以上の作業を並行して進めると、価値を生み出す作業に使える時間が大幅に減少することがわかった</li>
<li>2つの作業を変更に進めると、片方の作業が進められなくなったときに、もう片方の作業に切り替えることができるため、効率があがる</li>
</ul>


<p>僕達はずっと兼務を続けていた。しかも兼務をしているにもかかわらずアジャイルの中でのタスク割り振りまで重複して行ってしまっていた。これはまずい。
これは理由はどうあれ効率が落ちるからだ。データが示している。タスクAとタスクBをこなす必要があるのであれば、必ずAの次にBだ(もちろんBの次にAでもいいが同時はダメだ)
本の中では2つのタスクは気分転換の意味もあり、少しではあるが１０%ほど効率があがると書いてあるが、僕達はそもそもが兼務で集まったチームなのでダメだ。
人間は最大のパフォーマンスを発揮して且つ１度にできることは１つなのだと思う。マスターセンセイはこう言っていた。</p>

<blockquote><p>僕達みたいな普通の人がマルチタスクで片手間に作ったものなんて大したものができないんだよ</p></blockquote>


<p><img src="/images/posts/2013-10-18-agile_scrum/enough.png" alt="Enough!" /></p>

<p>非凡な才能溢れる人間でない限りは複数のことを１度に進めてはいけない。</p>

<h2>おまじないなんてない</h2>

<p>アジャイルで進めているプラクティスはどれもデータにもとづいて考えられたものだ。だからそこにおまじないはない。「どうしてこれをやっているんだろう」と思ったら
それは調べるべきだ。きっと答えはある。僕達はバーンダウンチャートを書いていく上で正規のタスク見積もり線の上に３掛けした線をもう一本引いていた。
どうしてかって。僕達がお手本にしていたプロジェクトが行っていたからだ。でもその理由は知らない。さりげなくそのことについてマスターセンセイに聞いた。</p>

<blockquote><p>上の線は本来はメンバーの持てるのすべての時間を表す。そこから７掛けして見積もり線を出せば各タスクのバッファを考えずにスプリント単位でずれを吸収してくれるんだよ</p></blockquote>


<p>なるほど、そういうことだったのか。</p>

<p>ちなみにこの７割という数字も多くのプロジェクトを研究して出した数字らしい。</p>

<p><img src="/images/posts/2013-10-18-agile_scrum/magic.png" alt="magic" /></p>

<p>教訓：疑問に思ったら調べろ</p>

<h2>まとめ</h2>

<p>３ヶ月で何が分かるかというぐらいアジャイルは奥深い。けれど最後に書いたようにアジャイルスクラムは魔法のメソッドなんてものではなくて、自分で考え試行錯誤していかなくちゃいけないものだとわかった。</p>

<p>でもひとつ大事なことは、アジャイルには「無理をしない」という点で１つ筋が通っているような気がした。できるものはできないし、できないものはできない。そのことをなんとなしに言ってしまうのではなくきちんと計測可能な数値で考えることができるフレームワークがアジャイルスクラムなのだと思う。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/04/paseputoronfalseshi-zhuang/">Scalaでパーセプトロンを作った</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-04T23:10:00+09:00" pubdate data-updated="true">Oct 4<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>PRMLの線形識別モデルの章の内容。PRMLの中に書いてある線形識別モデルをざっと実装しようと思っていたけれど、
最小二乗法に依る識別とフィッシャーの線形識別は割りとけちょんけちょんにけなされているイメージだったので、とりあえずおいておくことにします。</p>

<p>というわけでパーセプトロンを作ってみたよ。
今回もソースは<a href="https://github.com/PhysicsEngine/cpi-stats">ここ</a></p>

<p>パーセプトロンは誤分類を行ったデータに対してのみパーセプトロン基準にもとづいて重みベクトルを変化させていくアルゴリズム。このアルゴリズムは基本的には
2クラスの分類にだけしか使えないが、線形分類可能なデータ集合に対しては有限ステップで必ず分類できるモデルを構築できるという特徴と持つ。すごい！</p>

<h2>パーセプトロン規準</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">phi</span> <span class="k">=</span> <span class="nc">DenseVector</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">point</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">point</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</span><span class='line'><span class="n">phi</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">*</span> <span class="nc">_eta</span>
</span></code></pre></td></tr></table></div></figure>


<p>データ点にバイアスを加えたベクトルphiとデータ点の目的値(-1, 1)の積がパーセプトロン規準になる。この値は正しく分類されているデータに対しては常に正の値になる。つまりこの値が負の場合だけ重みベクトルを更新するように書くことができる。</p>

<p>こんな感じに書いた。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">plist</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">point</span> <span class="k">=&gt;</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">phi</span> <span class="k">=</span> <span class="nc">DenseVector</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">point</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">point</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</span><span class='line'>      <span class="k">if</span> <span class="o">((</span><span class="nc">_w</span><span class="o">.</span><span class="n">t</span> <span class="o">*</span> <span class="n">phi</span><span class="o">).</span><span class="n">apply</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="nc">_w</span> <span class="o">+=</span> <span class="n">phi</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">*</span> <span class="nc">_eta</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>すべての点に対してパーセプトロン規準に従い更新処理をかける。PRMLでは確率的最急降下アルゴリズムで更新をかける式が書いてあったので後でそちらも試してみる。
ここで注意しておきたいのは、パーセプトロンでは学習中に重みベクトルが変化すると正しく分類されていたパターンも誤分類されてしまうことがある。そのため、すべてのパターンが正しく分類されているかを再度検証する必要がある。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="n">plist</span><span class="o">.</span><span class="n">foreach</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">point</span> <span class="k">=&gt;</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">phi</span> <span class="k">=</span> <span class="nc">DenseVector</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">point</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">point</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</span><span class='line'>      <span class="k">if</span> <span class="o">((</span><span class="nc">_w</span><span class="o">.</span><span class="n">t</span> <span class="o">*</span> <span class="n">phi</span><span class="o">).</span><span class="n">apply</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>この<code>correct</code>がデータ点と等しくなったら学習を終える。
パーセプトロンははじめに線形分離可能なモデルならば<em>必ず</em>分離できるモデルを構築できるが、そうでない場合はいつまでも収束しない。そのため、もしそのようなデータ集合を与えた場合は上記の<code>correct</code>はずっとデータ点数を同じにならない。</p>

<p>今回は2次元上に2クラスの学習用データ集合を生成。それぞれのクラスの平均、共分散行列は固定で書いてあとは良きにはからってpylabに生成してもらった。</p>

<p>さて、実際にどのような感じか見てみる。</p>

<p><img src="/images/posts/2013-10-04-perceptron/N=100.png" alt="N=100" /></p>

<p>初期の重みベクトルはすべて要素が1の単純なベクトルで行った。それでもこの処理にかかったステップ数は３とかなり少ない。
PRMLではパーセプトロン学習アルゴリズムが収束するのに必要なステップ数はかなり多いと書いてあったけれど思っていたよりは少ない。もちろん2次元空間上で、尚且つたかだかデータ点数が100なので総結論づけれれないけれど、あくまでも思っていたよりかはということ。</p>

<p>結構分類が難しそうなものもやってみた。</p>

<p><img src="/images/posts/2013-10-04-perceptron/difficult.png" alt="難しそう" /></p>

<p>きちんと分類できている。これも重みベクトルの初期値は同じ。ステップ数も変わらない。つまりあくまでも初期値と線形分離可能性に大きく依存するので、あんまりクラス集合が近いとか遠いとか関係ないみたい。そこら辺は最小二乗法と大きく違うところ。</p>

<p>線形分離不可能なものもやってみた。</p>

<p><img src="/images/posts/2013-10-04-perceptron/impossible.png" alt="線形分離不可能" /></p>

<p>はい、やっぱりダメ。実際には収束しないので途中でプログラムを切って得た画像。</p>

<p>10minくらい走らせたけどダメだった。終わらない。</p>

<h2>確率的最急降下法</h2>

<p>さっきまでは全点を選んでの最急降下法で重みベクトルを更新していったけれど、PRMLに書いてあるように確立的最急降下法で計算してみるとどうだろう。計算コスト的にはかなり小さくなるはずだけれど、ステップ数も増えなければ最急降下法での計算の方が良さそう。どうなるか試してみたい。</p>

<p>実装としては以下のようにした。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">index</span> <span class="k">=</span> <span class="nc">Math</span><span class="o">.</span><span class="n">floor</span><span class="o">(</span><span class="nc">Math</span><span class="o">.</span><span class="n">random</span><span class="o">()*</span><span class="n">plist</span><span class="o">.</span><span class="n">length</span><span class="o">).</span><span class="n">toInt</span>
</span><span class='line'><span class="k">val</span> <span class="n">point</span> <span class="k">=</span> <span class="n">plist</span><span class="o">(</span><span class="n">index</span><span class="o">)</span>
</span><span class='line'><span class="k">val</span> <span class="n">phi</span> <span class="k">=</span> <span class="nc">DenseVector</span><span class="o">(</span><span class="mf">1.0</span><span class="o">,</span> <span class="n">point</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">point</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
</span><span class='line'><span class="k">if</span> <span class="o">((</span><span class="nc">_w</span><span class="o">.</span><span class="n">t</span> <span class="o">*</span> <span class="n">phi</span><span class="o">).</span><span class="n">apply</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>  <span class="nc">_w</span> <span class="o">+=</span> <span class="n">phi</span> <span class="o">*</span> <span class="n">point</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span> <span class="o">*</span> <span class="nc">_eta</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>データ点の中からランダムに1点を選び、その点に対してパーセプトロン規準に従い重みベクトルを更新する。</p>

<p>さて、やってみた。</p>

<p><img src="/images/posts/2013-10-04-perceptron/step=3.png" title="step=3" alt="step=3" /><img src="/images/posts/2013-10-04-perceptron/step=1069.png" title="step=1069" alt="step=1069" /></p>

<p>分類結果は当然変わらない。線形分類可能なら必ず収束する。左が先ほどまでの全点選択での最急降下法。右が確率的最急降下法。</p>

<p>ただしステップ数が大きく異なる。全点選択はステップ数3に対して確率的最急降下法はステップ数が1069！</p>

<p>確率的に降下方向を選ぶのは全点選ぶのと対して変わらないとどっかに(PRMLではない)書いてあったのに、結構違う。
もちろん全点選択の場合は1ステップで今回200点のループを回しているので実質600ほどのパーセプトロン規準での計算を行っている。それでも確率的最急降下法の方が多い。</p>

<p>個人的には確率的最急降下法は計算コストもかからないし、精度も対して落ちないかなり良さげなアルゴリズムだと思っていたのでちょっと意外だった。まあもちろんデータ点の数や状態、あとは重みベクトルの初期値なんかでもいろいろ変わってくると思うので一概には言えないですよね。</p>

<p>パーセプトロン奥が深いです</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/29/moderuebidensufalseping-jia/">モデルエビデンスの評価</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-29T10:17:00+09:00" pubdate data-updated="true">Sep 29<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>作ったプログラムは以下においたよ。</p>

<p><a href="https://github.com/PhysicsEngine/cpi-stats">https://github.com/PhysicsEngine/cpi-stats</a></p>

<p>ここで作成した線形回帰モデルのエビデンス評価をしてみた。
モデルエビデンスはざっくり言うと、訓練データを与える尤度を周辺化した値。つまり、そのデータを与える可能性が最も高いものを選ぶことができればパラメタの複雑さなどを自分で判断しなくてもよいというメリットがある。</p>

<p>今回、実装したのは基底関数を多項式とした場合で各目標値には加法性のガウスノイズがのる前提で計算を行った。</p>

<p>超パラメタalpha(モデルパラメタのばらつき)とbeta(ガウスノイズの精度)はそれぞれ0.0001、15.0にした。推定の方法としてはベイズ推定の予測分布を計算して行った。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// Mはモデルパラメタの数</span>
</span><span class='line'><span class="k">val</span> <span class="n">bayesRegression</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BayesRegression</span><span class="o">(</span><span class="n">M</span><span class="o">,</span> <span class="mf">0.0001</span><span class="o">,</span> <span class="mf">15.0</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<h1>モデルエビデンスの評価</h1>

<p>基本的にはPRML(3.86)式に従った。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="c1">// Alphaはパラメタの分布の事前分布のばらつきを表す超パラメタ</span>
</span><span class='line'><span class="c1">// Betaはガウスノイズの精度を表す超パラメタ</span>
</span><span class='line'><span class="c1">// eMnの最大尤度での二乗和誤差</span>
</span><span class='line'><span class="o">(</span><span class="n">M</span><span class="o">/</span><span class="mf">2.0</span><span class="o">)</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="nc">Alpha</span><span class="o">)</span> <span class="o">+</span> <span class="o">(</span><span class="n">xlist</span><span class="o">.</span><span class="n">length</span><span class="o">/</span><span class="mf">2.0</span><span class="o">)</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="nc">Beta</span><span class="o">)</span> <span class="o">-</span> <span class="n">eMn</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="mf">2.0</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="n">det</span><span class="o">(</span><span class="n">inv</span><span class="o">(</span><span class="nc">_sN</span><span class="o">)))</span> <span class="o">-</span> <span class="n">xlist</span><span class="o">.</span><span class="n">length</span> <span class="o">/</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="n">log</span><span class="o">(</span><span class="mi">2</span> <span class="o">*</span> <span class="nc">Math</span><span class="o">.</span><span class="nc">PI</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="/images/posts/2013-09-29-ModelEvidense/evidense.png" alt="モデルエビデンス" /></p>

<p>モデルエビデンスをモデルパラメタの複雑さ2~100の間でプロットした。赤線はM=4の位置。M=4で最大となっていることがわかる。というわけでそれぞれの主要な位置で実際のモデルのグラフをプロットしてみた</p>

<h2>M=3の場合</h2>

<p>なんか直線っぽく見えるけれど、二次関数です。ほぼあってないのでエビデンスもすごい低い。二乗和誤差関数の値も大きい。
このモデルはエビデンスを求めなくても選ばれなさそう。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=3.png" alt="M=3" /></p>

<h2>M=4の場合</h2>

<p>エビデンスが最大のモデル。見た目かなりよくfittingしている。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=4.png" alt="M=4" /></p>

<h2>M=9の場合</h2>

<p>むむ、M=4の場合と対して変わらない。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=9.png" alt="M=9" /></p>

<h2>M=15の場合</h2>

<p>これもあんまり変わらない。対数尺度で見た時に10程度の差しかないからか。この差はエビデンスでみると大して大きな差ではないのかもしれない。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=15.png" alt="M=15" /></p>

<h2>M=30の場合</h2>

<p>over fittingし始めた。M=15とM=30で大きく異るところはエビデンスの値というよりは訓練データ集合が25個だからそれより多いか少ないかの違いな気がする。</p>

<p>直感的には基底関数を多項式にしているので最尤推定で行うと訓練データ集合よりもモデルパラメータの数が多いとすべての点を通るようなグラフになる。今回はベイズ推定で行っているので事前分布のお陰で全点を通るなんてことはないけれど、それでも過学習をし始める分岐点としては訓練データの数になるかもしれない。</p>

<p>x=1付近でしか過学習してないのが気になるけれど。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=30.png" alt="M=30" /></p>

<h2>M=100の場合</h2>

<p>もう右側(x=1付近)のグラフはめちゃめちゃ。でもx=0付近はそんなにおかしくないのはなぜだろう。事前分布における精度は常に一定なのでそんなに場所によってばらついたりしなさそうなんだけど。</p>

<p><img src="/images/posts/2013-09-29-ModelEvidense/M=100.png" alt="M=100" /></p>

<h1>まとめ</h1>

<p>評価値xによって過学習したりしてなかったりするのが気になるけれど、全体としてはエビデンス関数を最大化するようなモデルパラメタMを選ぶことによって、最適なモデルを作ることができそう。PRMLにも書いてあったけれど、「目で見りゃいいじゃん」というのはもっと高次元になった場合に通用しなくなるので、解析的にモデルを評価できる手法は有用。しかも割と時間もそんなにかからない。(Scalaでモデル100個の評価を行ったけれど1~2秒ほど)</p>

<p>超パラメタ、alphaとbetaに関しても評価してエビデンスを最大化してみるとよりよいモデルが得られるのかも。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/28/devopsday-tokyo-2013nixing-tutekitayo/">DevOpsDay Tokyo 2013に行ってきたよ</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-28T10:37:00+09:00" pubdate data-updated="true">Sep 28<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><img src="/images/posts/2013-09-28-DevOpsDay/DevOpsDay-2013.jpg" alt="ノベルティ" /></p>

<p>印象に残った話しをざっとまとめてみる。なぜならBlogをかくまでがDev Ops Dayだから！！</p>

<h1>&ldquo;Making Operations Visible&rdquo; Nick Galbreath</h1>

<p>使いやすいツールとか紹介</p>

<p>DevOpsとはコミュニケーション（マシン間、人間の間、組織の間）</p>

<p>ビジネス側から見えないから価値がない</p>

<p>DevとOpsとBizで相互不信的な感じになると Destructiveですよね。だから、データを使おう（運用としてだけではなく、会社の仕組みとして）</p>

<p>ビジネス視点でのDevOpsと大事なことはコミュニケーションだと言い切ったところが新鮮だった。</p>

<p>Graphiteという統計可視化ツールの話。</p>

<p><a href="https://github.com/graphite-project">https://github.com/graphite-project</a></p>

<p>Diamond brightcoveは使いやすい</p>

<p>StatsDの話。
リアルタイムに統計計算をしてくれる。ログイン回数とか。それをGraphiteに書き込んでいく。特徴的なのはUDPパケットで送信を行うところ。そのためアプリケーション自体には過負荷にならない。またハンドリングとか要らないからエラーが起きない、必要ない。</p>

<h1>&ldquo;introduction to Sensu&rdquo; Sean Porter</h1>

<p>Sensuのお話。いろいろな機能をひとつにまとめて使いやすくしたよ。大事なコンセプトは以下。</p>

<ul>
<li>Autmatic client registration</li>
<li>Utilize existing Nagios checks</li>
<li>Handle network interrunptions</li>
<li>Easy to drive with CM(chef)</li>
<li>Easy to scale out</li>
<li><strong>API</strong></li>
</ul>


<p>Sonial（スポンサー）でしばらく使ってみて役に立つことがわかった</p>

<p>Sensuのワークフローとしては</p>

<ol>
<li>Check</li>
<li>Result</li>
<li>Event</li>
<li>Handle</li>
</ol>


<p>マシンの集まりに対して設定できる(roleみたいなものが設定できる)
JSONの設定ファイルを書いていくだけで使える。割と設定は簡単そう。
SensuはChefと相性が良さそう。</p>

<p>PagerDutyはテキストにもとづいてロボットが電話をかけてくる。日本で作りたい場合はTwilio使ってみましょうということだった。USBに入れられたVirtualBoxのimage入りのsandboxが配られた。すごいセットアップ簡単！
個人的にはGraphiteは見た目あんまりかっこよくないけど、SensuのSenseはいい（笑）</p>

<p>Chef + Sensu + PagerDutyは使えそう。今度自前で立ててみたい。</p>

<p>そして、お昼ごはん！久々の石巻復興弁当！</p>

<p><img src="/images/posts/2013-09-28-DevOpsDay/DevOpsDay-2013_2.jpg" alt="石巻復興弁当" /></p>

<p>途中からスポンサーさんのセッション。</p>

<p>Microsoftの偉大さと力強さを改めて実感。</p>

<h1>&ldquo;Taking Devops to the Next Level&rdquo; Max Martin</h1>

<p>puppet labsの話 DepOpの次の段階へ。
Chefがもてはやされているけれど、Puppetも頑張っているよという話。
最近以下のアップデートとか頑張ったよ。</p>

<ul>
<li>Puppet3.x</li>
<li>Hiera integration</li>
<li>PuppetDB</li>
<li>Mcollective2.x</li>
<li>Geppetto</li>
<li>Puppet Forge</li>
<li>Puppet3.xは2.xとくらべてだいぶパフォーマンス上がったよ</li>
<li>PuppetDBはClojureで書かれているよ、BaseはPostgreSQL、JVM上で動くよ</li>
</ul>


<p>僕は用事があったのでここまで。DevOpsの概念というかスタンスみたいなものが結構聞けたのが収穫。技術的には、Sensuは自前で立てていろいろ弄ってみたいなと思った。</p>

<p>朝早起きだったから眠かったけれど、楽しいセッションばかりで良かった！</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/20/neo4jfalseshi-ifang-1/">Neo4jの使い方(1)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-20T21:33:00+09:00" pubdate data-updated="true">Sep 20<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Neo4jを使ってみたよ。とりあえず触ってみたかったのでインストールはせずに<a href="http://gist.neo4j.org/">GraphGist</a>を使ってCypherの書き方を勉強してみた。</p>

<h1>Cypherって？</h1>

<p>グラフデータベースを操作するためのSQLのこと。他のグラフデータベースに利用されているのかは知らないけれどNeo4jに関してはこのCypherを使ってデータを操作する。SQLを知らないとMySQLに対して何もできないのと同じようにCypherを知らないとNeo4jを何もできない。今回はこのCypherの基本的な構文や書き方を書いてみる。</p>

<p>本家のドキュメントは<a href="http://docs.neo4j.org/chunked/milestone/cypher-query-lang.html">ここ</a>だよ</p>

<h1>ノードの作成</h1>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE (n:Actor {name:"Doraemon"})</span></code></pre></td></tr></table></div></figure>


<p>Actorは型。nameは属性。nはマッチさせるときの記述子</p>

<h2>エッジの作成</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (actor:Actor)
</span><span class='line'>WHERE actor.name = "Doraemon"
</span><span class='line'>CREATE (n:Actor {name:"Nobita"})
</span><span class='line'>CREATE (actor)-[:HELP]-&gt;(n)</span></code></pre></td></tr></table></div></figure>


<p>Actor型の中でnameがDoraemonのものを探す。見つけたらNobitaを作成し、その間にHELP型のエッジを作成する。</p>

<h2>UNIQUEで作成する</h2>

<p>エッジを同じものを複製したくなければ<code>CREATE UNIQUE</code>を使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (actor:Actor)
</span><span class='line'>WHERE actor.name = "Doraemon"
</span><span class='line'>CREATE UNIQUE (actor)-[r:ACTED_IN]-&gt;(movie:Movie {title:"Mugen Sankenshi"})
</span><span class='line'>RETURN r;</span></code></pre></td></tr></table></div></figure>


<h2>属性の変更</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (actor:Actor)
</span><span class='line'>WHERE actor.name = "Doraemon"
</span><span class='line'>SET actor.birth_year = 2020
</span><span class='line'>RETURN actor.name, actor.birth_year;</span></code></pre></td></tr></table></div></figure>


<h2>全てのノードの列挙</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (actor:Actor)
</span><span class='line'>RETURN actor as `All Actors`;</span></code></pre></td></tr></table></div></figure>


<h1>パターンマッチ</h1>

<p>グラフデータベースの検索は基本的にパターンマッチを使って行う。既にいくつか出てきたけれどパターンマッチには<code>MATCH</code>文を使う。</p>

<h2>エッジのマッチ</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(a)-[r]-&gt;(b)</span></code></pre></td></tr></table></div></figure>


<p>ノードは丸括弧で囲み、エッジは角括弧で囲む。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(a)-[r:HELP]-&gt;(b)</span></code></pre></td></tr></table></div></figure>


<p>型にもマッチさせたいときに型も書く。
無向グラフであれば矢印にはしない.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(a)--(b)</span></code></pre></td></tr></table></div></figure>


<p>複数のタイプにorでマッチさせたいときには縦棒を使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(a)-[r:TYPE1|TYPE2]-&gt;(b)</span></code></pre></td></tr></table></div></figure>


<h2>Optional relationship</h2>

<p>マッチしない場合にはその要素だけnullを返して欲しい場合には<code>?</code>を使う。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START me = node(*)
</span><span class='line'>MATCH (me)--&gt;(friend)-[?]-&gt;(friend_of_friend)
</span><span class='line'>RETURN friend,friend_of_friend</span></code></pre></td></tr></table></div></figure>


<p>この場合にはこの関係にマッチしないノードがあった場合にはそこの欄だけnullになる。関係があるかないかまだわからないけれど、とりあえずすべての見てみたい場合に有効。</p>

<p>エッジの個数を指定したい場合は<code>*</code>を使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START me = node(4)
</span><span class='line'>MATCH (me)-[?*2]-&gt;(friend)
</span><span class='line'>RETURN friend</span></code></pre></td></tr></table></div></figure>


<p>自分から２つ関係をまたいだ友達だけ返す。範囲指定も可能。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START me = node(4)
</span><span class='line'>MATCH (me)-[?*2..4]-&gt;(friend)
</span><span class='line'>RETURN friend</span></code></pre></td></tr></table></div></figure>


<p>2から4までの関係をまたいだ友達。</p>

<h2>パスの割り当て</h2>

<p>マッチしたパスを見たい場合があるときは、そのまま代入させてしまえばいい。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START me = node(3)
</span><span class='line'>MATCH p1 = (me)-[*2]-(friendOfFriend)
</span><span class='line'>CREATE p2 = (me)-[:MARRIED_TO]-&gt;(wife {name:"Gunhild"})
</span><span class='line'>CREATE UNIQUE p3 = wife-[:KNOWS]-friendOfFriend
</span><span class='line'>RETURN p1,p2,p3</span></code></pre></td></tr></table></div></figure>


<h1>参照構文</h1>

<p>要素の検索、参照に必要な４つの構文(START, MATCH, WHERE, RETURN)に関して</p>

<h2>START</h2>

<p>STARTは探索を行うためのアンカーとなるノード、またはエッジを決める構文。</p>

<p>以下のようなグラフがあったときに</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START n = node(1)</span></code></pre></td></tr></table></div></figure>


<p>と書くとnにnodeの1がバインドされ、これを使って探索することが可能。</p>

<p><img src="/images/posts/2013-09-20-neo4j-1/graph.png" alt="Graphの例" /></p>

<p>複数ノード、または全てのノードに対して処理を行いたい場合はこんな感じ。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START n = node(1,2,3)
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START n = node(*)
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>アンカーとなるエッジをバインドさせたい場合は以下のように書く。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START r = relationship(0)
</span><span class='line'>RETURN r</span></code></pre></td></tr></table></div></figure>


<p>複数の点から始めるにはこんな感じ。(このやり方が知りたかった)</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>START a = node(1), b = node(2)
</span><span class='line'>RETURN a,b</span></code></pre></td></tr></table></div></figure>


<h2>MATCH</h2>

<p>nodeやエッジにパターンマッチさせるための構文。
STARTなしでもMATCHは使えることはさっき書いたけれど、この場合でのどちらにしろCypherはすべてのノードを探索して始点となるノードを探すことになる。</p>

<p>すべてのノードを得たい場合は簡単。CypherはSTARTを指定しなければすべてのノードを探索するので、条件がなければすべてのノードにマッチする。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>ラベルにマッチさせたいときはコロンで区切る</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n:Actor
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>エッジもマッチに含めてよい</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (director)--&gt;(movie)
</span><span class='line'>WHERE director.name = "Oliver Stone"
</span><span class='line'>RETURN movie.title</span></code></pre></td></tr></table></div></figure>


<p>エッジにラベルをマッチさせてもよい</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (movie)&lt;-[r:ACTED_IN]-(actor)
</span><span class='line'>WHERE actor.name = "Tom Hanks"
</span><span class='line'>RETURN movie.title</span></code></pre></td></tr></table></div></figure>


<p>エッジの数でマッチさせることもできる</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (martin)-[:ACTED_IN*1..2]-(x)
</span><span class='line'>WHERE martin.name = "Martin Sheen"
</span><span class='line'>RETURN x</span></code></pre></td></tr></table></div></figure>


<h2>WHERE</h2>

<p>MATCHで引っかかったものをfilterにかける処理を行う文</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n
</span><span class='line'>WHERE n.name = "Takeshi" XOR (n.age &lt; 30 AND n.name = "Nobita") OR NOT (n.name = "Suneo" OR n.name = "Dekisugi")
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>名前がたけしである場合か、30際以下ののび太である場合かスネオでも出来杉でもない場合のノードが返ってくる
MATCHでラベルを使うこともできたが、WHEREでも可能</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n
</span><span class='line'>WHERE n:Actor
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>Actorだけが返ってくる。また正規表現も使える</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n
</span><span class='line'>WHERE n.name =~ "T.*"
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>多分&#8221;Takeshi&#8221;が返ってくる。ある属性があるかないかで取る場合はHASを使う</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH n
</span><span class='line'>WHERE HAS(n.belt)
</span><span class='line'>RETURN n</span></code></pre></td></tr></table></div></figure>


<p>belt属性があるものが得られる。</p>

<h2>RETURN</h2>

<p>返り値を選択するのがRETURN文だけれどここで数を返した、平均を返したりといったことができる。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (n)--&gt;(x)
</span><span class='line'>WHERE n.name = "X"
</span><span class='line'>RETURN n, count(*)</span></code></pre></td></tr></table></div></figure>


<p>MATCHした数が返ってくる。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MATCH (n)-[r]-&gt;(x)
</span><span class='line'>WHERE n.name = "Nobita"
</span><span class='line'>RETURN type(r)</span></code></pre></td></tr></table></div></figure>


<p>エッジのラベルが返ってくる。KNOWSとか。
SQLと同じように他にもSUMとかAVGとか使えるみたい。</p>

<p>大体基本的な構文はわかってきたので、次はGraphGistを使ってもう少し複雑なものを作ってみようかな。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/18/zhi-shi-biao-xian-falsetamefalsedetagou-zao/">知識表現のためのデータ構造</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-18T21:15:00+09:00" pubdate data-updated="true">Sep 18<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>知識表現</h2>

<blockquote><p>知識表現（ちしきひょうげん）、KR（Knowledge Representation）は、推論を導けるような知識の表現、およびその方法を開発する人工知能研究の領域である。</p><footer><strong>From</strong> <cite><a href='http://ja.wikipedia.org/wiki/%E7%9F%A5%E8%AD%98%E8%A1%A8%E7%8F%BE'>ja.wikipedia.org/wiki/&hellip;</a></cite></footer></blockquote>


<p>人工知能って何って考えたときにぼんやりと、何かの入力に対して何らかの&#8221;知識&#8221;を使って出力を行う機械というふうに考えていた。そもそも漠然とはしている答えではあるものの、じゃあ&#8221;知識&#8221;って何？どうやって得ればいいの？どうやって持っていればいいの？という考えになる。それに答えを与えるのが知識表現(Knowledge Representation)だ。</p>

<p>この知識のデータ構造は推論がしやすい形で持っているのがいい。そしてさらに、表現力がちょうどよい方がいい。なぜなら表現力が高ければ高いほど、記述自体は簡潔になるが、推論に一貫性が持たせられないかもしれない。逆に表現力が低いと非常に煩雑な記述を行わないといけないかもしれない。そのためこのちょうどとい程度の表現力の知識表現は大事だ。</p>

<h3>フレーム構造</h3>

<p>RDBMSみたいなもの。知識を事柄の名称、事柄の属性、属性の値で表現する。RDBMS的にいうとPKとカラム名、カラム値に対応するのかな。</p>

<p><img src="https://raw.github.com/Lewuathe/lewuathe.github.io/source/ownimage/frame.png" alt="フレーム構造" /></p>

<p>ただフレーム構造はその事柄の属性をすべて列挙することが非常にむずかしいことがわかっている(フレーム問題)</p>

<h3>スクリプト構造</h3>

<p>スクリプト構造は手続き的な知識の知識表現に使える。</p>

<p><img src="https://raw.github.com/Lewuathe/lewuathe.github.io/source/ownimage/script.png" alt="スクリプト構造" /></p>

<h3>格文法</h3>

<p>動詞を中心にとらえて、用言的概念と体言的概念に整理する。少しむずかしいが概念を文法として理解しようという試み。情報通信研究機構で開発が続くEDR電子化辞書などの用いられているらしい。</p>

<h3>概念依存理論</h3>

<p>どんな言語にも共通する根源的な意味を抽出して、それらの意味ですべてを表現しようという試み。すべての文章を11の動詞の組み合わせと名詞、修飾概念などを組み合わせて表現。各文法はどちらかというと「関係」に重きをおいた表現方法だが、概念依存理論は「概念」それ自身をを中心に据えている。</p>

<p><img src="https://raw.github.com/Lewuathe/lewuathe.github.io/source/ownimage/gainen.png" alt="概念依存理論" /></p>

<h3>意味ネットワーク</h3>

<p>意味ネットワークは物事をその関係性から評価しようという試み。今まで出てきた属性や、承継関係、動作対象なども「関係」として表すことができるので、すべての知識をノードとエッジで表せる。この方法のよいところは、物事を関係性から理解しようとするので、その物事について関係性が現れるまで評価する必要がないところだと思う。実際人間と同じように考えるのであれば、ある物事を理解しようとするときにそれを直ちに理解しようとするよりは、まず周りとの関係性（それがどのような関係性であれ）から埋めていくことが多い。初対面の人を知ろうとするときに、その人の職業、年齢、性別、住所などから理解しようとすることと同じだ。</p>

<h2>結論</h2>

<p>結論というと言い過ぎかもしれない。僕自身が考えたこととしては知識を表現する上であるオブジェクトの属性や承継関係などをそれぞれ区別して理解しようとするとあまりに煩雑にすぎる気がした。そのためもっと上位のネットワーク構造という形から知識を表現できるようにするといいんじゃないかと思った。実際上記のすべての知識表現はノードとエッジという構造で表現できそうだ。つまり意味ネットワークとしての知識表現をベースにしたものが最も適していると思う。</p>

<p>さて、知識の表現方法は分かった。じゃあこれをどうやってデータとして持てばいいんだろう。ちょうどいいところに最近ではNoSQLの一つとしてグラフ志向データベースというものがあるらしい。これは文字通りデータをノードとエッジの組み合わせで表現する方法。ノード間の関係性などが探索するのに非常に適していいるらしい。最も有名なところではNeo4Jというものがある。</p>

<p><a href="http://www.neo4j.org/">http://www.neo4j.org/</a></p>

<p>なんだかここがGraphGistコンテストみたいなものをやっているっぽいので、勉強がてらやってみようかと。多分次回はNeo4Jに関して書くかも。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/6/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/4/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/03/25/shan-toshou-duan-tomu-de-to/">禅と手段と目的と</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/19/next-tile-on-tempai/">Next Tile on Tempai</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/18/marble-problem/">Marble Problem</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/17/srm144-div1/">SRM144 Div1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/11/forget-grief-keep-data/">Forget Grief, Keep Data</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Kai Sasaki -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/ja_JP/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
